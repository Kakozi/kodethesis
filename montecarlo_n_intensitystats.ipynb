{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f497a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5421282f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2717e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "meta = pd.read_csv('AnonDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb48efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Parameter stats (sampled) ===\n",
      "             mean           std            5%           50%           95%\n",
      "Ipv  8.999329e+00  2.688421e-01  8.568111e+00  8.995682e+00  9.451849e+00\n",
      "I0   9.975245e-11  8.450028e-11  2.447156e-11  7.682395e-11  2.426250e-10\n",
      "Rs   3.498114e-01  5.215127e-02  2.722976e-01  3.461650e-01  4.414029e-01\n",
      "Rp   7.922339e+02  2.335495e+02  4.711153e+02  7.622026e+02  1.219899e+03\n",
      "a    1.198938e+00  6.001090e-02  1.105873e+00  1.196331e+00  1.302274e+00\n",
      "Vt   1.559951e+00  3.083508e-02  1.510161e+00  1.559883e+00  1.611433e+00\n",
      "\n",
      "=== Sensitivity ranking (higher |PRCC| => more influential) ===\n",
      "  parameter  PRCC(Pmpp)  Spearman(Pmpp)  PRCC(I@V_eval)  Spearman(I@V_eval)\n",
      "0       Ipv    0.999991        0.999973        0.999992            0.999974\n",
      "1        Rp    0.797269        0.033640        0.791606            0.033378\n",
      "2        Rs   -0.488618       -0.006006       -0.499434           -0.006006\n",
      "3        I0   -0.036272        0.003335       -0.038014            0.003328\n",
      "4         a   -0.027059        0.008684       -0.030830            0.008679\n",
      "5        Vt    0.012002       -0.000734        0.014353           -0.000729\n",
      "\n",
      "Pmpp summary: count    3000.000000\n",
      "mean        6.475694\n",
      "std         0.193501\n",
      "min         5.818795\n",
      "25%         6.343514\n",
      "50%         6.473087\n",
      "75%         6.605382\n",
      "max         7.243918\n",
      "dtype: float64\n",
      "I(V_eval) summary: count    3000.000000\n",
      "mean        8.994253\n",
      "std         0.268750\n",
      "min         8.081883\n",
      "25%         8.810638\n",
      "50%         8.990701\n",
      "75%         9.174394\n",
      "max        10.061262\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Solver I(V) untuk SDM (implicit)\n",
    "# -----------------------------\n",
    "def solve_current_sdm(V, params, max_iter=80, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Solve I for a given V using Newton-Raphson.\n",
    "    params: dict with keys: Ipv, I0, Rs, Rp, a, Vt\n",
    "    \"\"\"\n",
    "    Ipv, I0, Rs, Rp, a, Vt = (\n",
    "        params[\"Ipv\"], params[\"I0\"], params[\"Rs\"], params[\"Rp\"], params[\"a\"], params[\"Vt\"]\n",
    "    )\n",
    "\n",
    "    # Initial guess: close to short-circuit current\n",
    "    I = np.clip(Ipv, 0, None)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        x = (V + I * Rs) / (a * Vt)\n",
    "\n",
    "        # avoid overflow\n",
    "        x = np.clip(x, -100, 100)\n",
    "        ex = np.exp(x)\n",
    "\n",
    "        # f(I) = I - Ipv + I0*(exp(x)-1) + (V + I*Rs)/Rp = 0\n",
    "        f = I - Ipv + I0 * (ex - 1.0) + (V + I * Rs) / Rp\n",
    "\n",
    "        # df/dI = 1 + I0*exp(x) * (Rs/(a*Vt)) + Rs/Rp\n",
    "        df = 1.0 + I0 * ex * (Rs / (a * Vt)) + (Rs / Rp)\n",
    "\n",
    "        step = f / df\n",
    "        I_new = I - step\n",
    "\n",
    "        if np.abs(I_new - I) < tol:\n",
    "            return float(I_new)\n",
    "\n",
    "        I = I_new\n",
    "\n",
    "    return float(I)  # return best effort\n",
    "\n",
    "\n",
    "def iv_curve(params, V_grid):\n",
    "    I = np.array([solve_current_sdm(V, params) for V in V_grid], dtype=float)\n",
    "    P = V_grid * I\n",
    "    return I, P\n",
    "\n",
    "\n",
    "def calc_pmpp(params, Voc_guess=0.72, nV=200):\n",
    "    \"\"\"\n",
    "    Approximate Pmpp by scanning V from 0 to Voc_guess.\n",
    "    For better accuracy, set Voc_guess based on your module/string.\n",
    "    \"\"\"\n",
    "    V_grid = np.linspace(0, Voc_guess, nV)\n",
    "    I, P = iv_curve(params, V_grid)\n",
    "    idx = int(np.nanargmax(P))\n",
    "    return float(P[idx]), float(V_grid[idx]), float(I[idx])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Sampling distributions (Monte Carlo)\n",
    "# -----------------------------\n",
    "def sample_lognormal(mean, cov, size, rng):\n",
    "    \"\"\"\n",
    "    lognormal with desired mean and coefficient of variation (std/mean).\n",
    "    Works for strictly positive parameters.\n",
    "    \"\"\"\n",
    "    mean = float(mean)\n",
    "    cov = float(cov)\n",
    "    # convert (mean, cov) -> lognormal mu, sigma\n",
    "    sigma2 = np.log(1 + cov**2)\n",
    "    sigma = np.sqrt(sigma2)\n",
    "    mu = np.log(mean) - 0.5 * sigma2\n",
    "    return rng.lognormal(mean=mu, sigma=sigma, size=size)\n",
    "\n",
    "\n",
    "def sample_normal(mean, std, size, rng):\n",
    "    return rng.normal(loc=mean, scale=std, size=size)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Rank + PRCC utilities\n",
    "# -----------------------------\n",
    "def rankdata(a):\n",
    "    # simple rank (ties handled approximately by average rank via pandas)\n",
    "    return pd.Series(a).rank(method=\"average\").to_numpy()\n",
    "\n",
    "def prcc(X, y):\n",
    "    \"\"\"\n",
    "    Partial Rank Correlation Coefficient:\n",
    "    - rank-transform all variables\n",
    "    - regress y on other X (excluding Xi), take residuals\n",
    "    - regress Xi on other X, take residuals\n",
    "    - corr(res_y, res_xi)\n",
    "    \"\"\"\n",
    "    Xr = np.column_stack([rankdata(X[:, j]) for j in range(X.shape[1])])\n",
    "    yr = rankdata(y)\n",
    "\n",
    "    # add intercept\n",
    "    ones = np.ones((Xr.shape[0], 1))\n",
    "    PRCC = np.zeros(Xr.shape[1], dtype=float)\n",
    "\n",
    "    for i in range(Xr.shape[1]):\n",
    "        idx_other = [j for j in range(Xr.shape[1]) if j != i]\n",
    "        X_other = np.column_stack([ones, Xr[:, idx_other]])\n",
    "\n",
    "        # residual of y ~ other\n",
    "        beta_y, *_ = np.linalg.lstsq(X_other, yr, rcond=None)\n",
    "        y_hat = X_other @ beta_y\n",
    "        ry = yr - y_hat\n",
    "\n",
    "        # residual of Xi ~ other\n",
    "        beta_x, *_ = np.linalg.lstsq(X_other, Xr[:, i], rcond=None)\n",
    "        x_hat = X_other @ beta_x\n",
    "        rx = Xr[:, i] - x_hat\n",
    "\n",
    "        # correlation\n",
    "        PRCC[i] = np.corrcoef(rx, ry)[0, 1]\n",
    "\n",
    "    return PRCC\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Main Monte Carlo simulation\n",
    "# -----------------------------\n",
    "def monte_carlo_sensitivity(\n",
    "    N=3000,\n",
    "    seed=42,\n",
    "    V_eval=0.55,          # evaluate current at a specific voltage (example)\n",
    "    Voc_guess=0.72,       # for Pmpp scanning\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # ---- Nominal parameters (EDIT sesuai modulmu) ----\n",
    "    # Ipv (A), I0 (A), Rs (ohm), Rp (ohm), a (-), Vt (V)\n",
    "    # NOTE: Vt = (kT/q) * Ns, jadi tergantung jumlah sel seri & temperatur\n",
    "    nominal = dict(\n",
    "        Ipv=9.0,\n",
    "        I0=1e-10,\n",
    "        Rs=0.35,\n",
    "        Rp=800.0,\n",
    "        a=1.2,\n",
    "        Vt=0.026 * 60,   # contoh: 60 sel seri @ ~300K => 1.56 V\n",
    "    )\n",
    "\n",
    "    # ---- Uncertainty assumptions (EDIT) ----\n",
    "    # Positive parameters -> lognormal (more realistic)\n",
    "    cov = dict(\n",
    "        Ipv=0.03,   # 3%\n",
    "        I0=0.80,    # I0 sering sangat variatif\n",
    "        Rs=0.15,\n",
    "        Rp=0.30,\n",
    "        a=0.05,\n",
    "        Vt=0.02,\n",
    "    )\n",
    "\n",
    "    # Sample parameters\n",
    "    samples = pd.DataFrame({\n",
    "        \"Ipv\": sample_lognormal(nominal[\"Ipv\"], cov[\"Ipv\"], N, rng),\n",
    "        \"I0\":  sample_lognormal(nominal[\"I0\"],  cov[\"I0\"],  N, rng),\n",
    "        \"Rs\":  sample_lognormal(nominal[\"Rs\"],  cov[\"Rs\"],  N, rng),\n",
    "        \"Rp\":  sample_lognormal(nominal[\"Rp\"],  cov[\"Rp\"],  N, rng),\n",
    "        \"a\":   sample_lognormal(nominal[\"a\"],   cov[\"a\"],   N, rng),\n",
    "        \"Vt\":  sample_lognormal(nominal[\"Vt\"],  cov[\"Vt\"],  N, rng),\n",
    "    })\n",
    "\n",
    "    # Outputs\n",
    "    I_at_V = np.empty(N, dtype=float)\n",
    "    Pmpp = np.empty(N, dtype=float)\n",
    "\n",
    "    for i in range(N):\n",
    "        p = samples.iloc[i].to_dict()\n",
    "        # output 1: current at V_eval\n",
    "        I_at_V[i] = solve_current_sdm(V_eval, p)\n",
    "\n",
    "        # output 2: Pmpp (approx) from IV scanning\n",
    "        Pmpp[i], _, _ = calc_pmpp(p, Voc_guess=Voc_guess, nV=220)\n",
    "\n",
    "    # Build X matrix\n",
    "    X = samples.to_numpy()\n",
    "    param_names = samples.columns.tolist()\n",
    "\n",
    "    # Spearman correlations (rank corr)\n",
    "    spearman_I = [np.corrcoef(rankdata(X[:, j]), rankdata(I_at_V))[0, 1] for j in range(X.shape[1])]\n",
    "    spearman_P = [np.corrcoef(rankdata(X[:, j]), rankdata(Pmpp))[0, 1] for j in range(X.shape[1])]\n",
    "\n",
    "    # PRCC\n",
    "    prcc_I = prcc(X, I_at_V)\n",
    "    prcc_P = prcc(X, Pmpp)\n",
    "\n",
    "    # Summary table\n",
    "    out = pd.DataFrame({\n",
    "        \"parameter\": param_names,\n",
    "        \"Spearman(I@V_eval)\": spearman_I,\n",
    "        \"PRCC(I@V_eval)\": prcc_I,\n",
    "        \"Spearman(Pmpp)\": spearman_P,\n",
    "        \"PRCC(Pmpp)\": prcc_P,\n",
    "        \"abs_PRCC(Pmpp)\": np.abs(prcc_P),\n",
    "        \"abs_PRCC(I@V_eval)\": np.abs(prcc_I),\n",
    "    }).sort_values(\"abs_PRCC(Pmpp)\", ascending=False)\n",
    "\n",
    "    # Add basic distribution info\n",
    "    desc = samples.describe(percentiles=[0.05, 0.5, 0.95]).T[[\"mean\", \"std\", \"5%\", \"50%\", \"95%\"]]\n",
    "    return out.reset_index(drop=True), desc, I_at_V, Pmpp, samples\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ranking, param_stats, I_at_V, Pmpp, samples = monte_carlo_sensitivity(\n",
    "        N=3000,\n",
    "        seed=1,\n",
    "        V_eval=0.55,\n",
    "        Voc_guess=0.72,\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Parameter stats (sampled) ===\")\n",
    "    print(param_stats)\n",
    "\n",
    "    print(\"\\n=== Sensitivity ranking (higher |PRCC| => more influential) ===\")\n",
    "    print(ranking[[\"parameter\", \"PRCC(Pmpp)\", \"Spearman(Pmpp)\", \"PRCC(I@V_eval)\", \"Spearman(I@V_eval)\"]])\n",
    "\n",
    "    print(\"\\nPmpp summary:\", pd.Series(Pmpp).describe())\n",
    "    print(\"I(V_eval) summary:\", pd.Series(I_at_V).describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6c166c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Parameter stats (sampled) ===\n",
      "             mean           std            5%           50%           95%\n",
      "Ipv  8.999329e+00  2.688421e-01  8.568111e+00  8.995682e+00  9.451849e+00\n",
      "I01  1.000214e-12  1.082598e-12  1.790592e-13  6.935898e-13  2.705770e-12\n",
      "I02  9.951594e-09  7.964748e-09  2.519365e-09  7.812658e-09  2.457510e-08\n",
      "Rs   3.483807e-01  5.147520e-02  2.703301e-01  3.451950e-01  4.383808e-01\n",
      "Rp   7.961015e+02  2.421510e+02  4.776887e+02  7.581389e+02  1.248085e+03\n",
      "a1   1.199884e+00  5.929598e-02  1.105659e+00  1.198876e+00  1.300339e+00\n",
      "a2   1.999032e+00  9.885115e-02  1.839057e+00  1.998528e+00  2.171442e+00\n",
      "Vt1  1.560024e+00  3.056834e-02  1.510718e+00  1.559143e+00  1.611664e+00\n",
      "Vt2  1.559857e+00  3.101535e-02  1.510423e+00  1.559115e+00  1.611607e+00\n",
      "\n",
      "=== Sensitivity ranking (sorted by |PRCC| on Pmpp) ===\n",
      "  parameter  PRCC(Pmpp)  Spearman(Pmpp)  PRCC(I@V_eval)  Spearman(I@V_eval)\n",
      "0       Ipv    0.999992        0.999975        0.999992            0.999977\n",
      "1        Rp    0.790758        0.014258        0.785337            0.014037\n",
      "2        Rs   -0.489097        0.025624       -0.500059            0.025620\n",
      "3       Vt1   -0.021231       -0.018608       -0.022048           -0.018613\n",
      "4       Vt2   -0.016820       -0.012975       -0.016785           -0.012978\n",
      "5       I01    0.016088        0.003331        0.016344            0.003336\n",
      "6        a2   -0.014766        0.022606       -0.013984            0.022614\n",
      "7       I02    0.013867       -0.003592        0.012270           -0.003599\n",
      "8        a1   -0.005476       -0.001129       -0.006657           -0.001126\n",
      "\n",
      "Pmpp summary:\n",
      " count    3000.000000\n",
      "mean        6.475716\n",
      "std         0.193485\n",
      "min         5.819926\n",
      "25%         6.343067\n",
      "50%         6.473415\n",
      "75%         6.605318\n",
      "max         7.244338\n",
      "dtype: float64\n",
      "\n",
      "I(V_eval) summary:\n",
      " count    3000.000000\n",
      "mean        8.994282\n",
      "std         0.268728\n",
      "min         8.083443\n",
      "25%         8.809970\n",
      "50%         8.991001\n",
      "75%         9.174405\n",
      "max        10.061832\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Solver I(V) untuk Double-Diode Model (implicit)\n",
    "# -----------------------------\n",
    "def solve_current_ddm(V, params, max_iter=100, tol=1e-11):\n",
    "    \"\"\"\n",
    "    Double diode model:\n",
    "    I = Ipv - I01*(exp((V+I*Rs)/(a1*Vt1)) - 1)\n",
    "            - I02*(exp((V+I*Rs)/(a2*Vt2)) - 1)\n",
    "            - (V + I*Rs)/Rp\n",
    "    Solve I for a given V using Newton-Raphson.\n",
    "    \"\"\"\n",
    "    Ipv = params[\"Ipv\"]\n",
    "    I01 = params[\"I01\"]\n",
    "    I02 = params[\"I02\"]\n",
    "    Rs  = params[\"Rs\"]\n",
    "    Rp  = params[\"Rp\"]\n",
    "    a1  = params[\"a1\"]\n",
    "    a2  = params[\"a2\"]\n",
    "    Vt1 = params[\"Vt1\"]\n",
    "    Vt2 = params[\"Vt2\"]\n",
    "\n",
    "    # initial guess: near short-circuit current\n",
    "    I = np.clip(Ipv, 0, None)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        x1 = (V + I * Rs) / (a1 * Vt1)\n",
    "        x2 = (V + I * Rs) / (a2 * Vt2)\n",
    "\n",
    "        # prevent overflow\n",
    "        x1 = np.clip(x1, -100, 100)\n",
    "        x2 = np.clip(x2, -100, 100)\n",
    "\n",
    "        ex1 = np.exp(x1)\n",
    "        ex2 = np.exp(x2)\n",
    "\n",
    "        # f(I) = I - Ipv + I01*(exp(x1)-1) + I02*(exp(x2)-1) + (V+I*Rs)/Rp = 0\n",
    "        f = I - Ipv + I01 * (ex1 - 1.0) + I02 * (ex2 - 1.0) + (V + I * Rs) / Rp\n",
    "\n",
    "        # df/dI = 1 + I01*exp(x1)*(Rs/(a1*Vt1)) + I02*exp(x2)*(Rs/(a2*Vt2)) + Rs/Rp\n",
    "        df = (\n",
    "            1.0\n",
    "            + I01 * ex1 * (Rs / (a1 * Vt1))\n",
    "            + I02 * ex2 * (Rs / (a2 * Vt2))\n",
    "            + (Rs / Rp)\n",
    "        )\n",
    "\n",
    "        step = f / df\n",
    "        I_new = I - step\n",
    "\n",
    "        if np.abs(I_new - I) < tol:\n",
    "            return float(I_new)\n",
    "\n",
    "        I = I_new\n",
    "\n",
    "    return float(I)\n",
    "\n",
    "\n",
    "def iv_curve_ddm(params, V_grid):\n",
    "    I = np.array([solve_current_ddm(V, params) for V in V_grid], dtype=float)\n",
    "    P = V_grid * I\n",
    "    return I, P\n",
    "\n",
    "\n",
    "def calc_pmpp_ddm(params, Voc_guess=0.72, nV=220):\n",
    "    V_grid = np.linspace(0, Voc_guess, nV)\n",
    "    I, P = iv_curve_ddm(params, V_grid)\n",
    "    idx = int(np.nanargmax(P))\n",
    "    return float(P[idx]), float(V_grid[idx]), float(I[idx])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Sampling distributions (Monte Carlo)\n",
    "# -----------------------------\n",
    "def sample_lognormal(mean, cov, size, rng):\n",
    "    mean = float(mean)\n",
    "    cov = float(cov)\n",
    "    sigma2 = np.log(1 + cov**2)\n",
    "    sigma = np.sqrt(sigma2)\n",
    "    mu = np.log(mean) - 0.5 * sigma2\n",
    "    return rng.lognormal(mean=mu, sigma=sigma, size=size)\n",
    "\n",
    "\n",
    "def rankdata(a):\n",
    "    return pd.Series(a).rank(method=\"average\").to_numpy()\n",
    "\n",
    "\n",
    "def prcc(X, y):\n",
    "    Xr = np.column_stack([rankdata(X[:, j]) for j in range(X.shape[1])])\n",
    "    yr = rankdata(y)\n",
    "\n",
    "    ones = np.ones((Xr.shape[0], 1))\n",
    "    PRCC = np.zeros(Xr.shape[1], dtype=float)\n",
    "\n",
    "    for i in range(Xr.shape[1]):\n",
    "        idx_other = [j for j in range(Xr.shape[1]) if j != i]\n",
    "        X_other = np.column_stack([ones, Xr[:, idx_other]])\n",
    "\n",
    "        beta_y, *_ = np.linalg.lstsq(X_other, yr, rcond=None)\n",
    "        ry = yr - (X_other @ beta_y)\n",
    "\n",
    "        beta_x, *_ = np.linalg.lstsq(X_other, Xr[:, i], rcond=None)\n",
    "        rx = Xr[:, i] - (X_other @ beta_x)\n",
    "\n",
    "        PRCC[i] = np.corrcoef(rx, ry)[0, 1]\n",
    "\n",
    "    return PRCC\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Main Monte Carlo sensitivity for DDM\n",
    "# -----------------------------\n",
    "def monte_carlo_sensitivity_ddm(\n",
    "    N=3000,\n",
    "    seed=1,\n",
    "    V_eval=0.55,\n",
    "    Voc_guess=0.72,\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # ---- Nominal parameters (EDIT sesuai modul/dataset kamu) ----\n",
    "    # Tipikal: I01 << I02 (atau sebaliknya tergantung model fit), dan I0 bisa sangat kecil\n",
    "    nominal = dict(\n",
    "        Ipv=9.0,\n",
    "        I01=1e-12,\n",
    "        I02=1e-8,\n",
    "        Rs=0.35,\n",
    "        Rp=800.0,\n",
    "        a1=1.2,\n",
    "        a2=2.0,\n",
    "        Vt1=0.026 * 60,   # Ns*Vt_cell @ ~300K\n",
    "        Vt2=0.026 * 60,\n",
    "    )\n",
    "\n",
    "    # ---- Uncertainty assumptions (EDIT) ----\n",
    "    cov = dict(\n",
    "        Ipv=0.03,\n",
    "        I01=1.00,   # sangat variatif\n",
    "        I02=0.80,\n",
    "        Rs=0.15,\n",
    "        Rp=0.30,\n",
    "        a1=0.05,\n",
    "        a2=0.05,\n",
    "        Vt1=0.02,\n",
    "        Vt2=0.02,\n",
    "    )\n",
    "\n",
    "    # Sample parameters (positive -> lognormal)\n",
    "    samples = pd.DataFrame({\n",
    "        \"Ipv\": sample_lognormal(nominal[\"Ipv\"], cov[\"Ipv\"], N, rng),\n",
    "        \"I01\": sample_lognormal(nominal[\"I01\"], cov[\"I01\"], N, rng),\n",
    "        \"I02\": sample_lognormal(nominal[\"I02\"], cov[\"I02\"], N, rng),\n",
    "        \"Rs\":  sample_lognormal(nominal[\"Rs\"],  cov[\"Rs\"],  N, rng),\n",
    "        \"Rp\":  sample_lognormal(nominal[\"Rp\"],  cov[\"Rp\"],  N, rng),\n",
    "        \"a1\":  sample_lognormal(nominal[\"a1\"],  cov[\"a1\"],  N, rng),\n",
    "        \"a2\":  sample_lognormal(nominal[\"a2\"],  cov[\"a2\"],  N, rng),\n",
    "        \"Vt1\": sample_lognormal(nominal[\"Vt1\"], cov[\"Vt1\"], N, rng),\n",
    "        \"Vt2\": sample_lognormal(nominal[\"Vt2\"], cov[\"Vt2\"], N, rng),\n",
    "    })\n",
    "\n",
    "    # Outputs\n",
    "    I_at_V = np.empty(N, dtype=float)\n",
    "    Pmpp   = np.empty(N, dtype=float)\n",
    "\n",
    "    for i in range(N):\n",
    "        p = samples.iloc[i].to_dict()\n",
    "        I_at_V[i] = solve_current_ddm(V_eval, p)\n",
    "        Pmpp[i], _, _ = calc_pmpp_ddm(p, Voc_guess=Voc_guess, nV=240)\n",
    "\n",
    "    X = samples.to_numpy()\n",
    "    param_names = samples.columns.tolist()\n",
    "\n",
    "    # Spearman\n",
    "    spearman_I = [np.corrcoef(rankdata(X[:, j]), rankdata(I_at_V))[0, 1] for j in range(X.shape[1])]\n",
    "    spearman_P = [np.corrcoef(rankdata(X[:, j]), rankdata(Pmpp))[0, 1] for j in range(X.shape[1])]\n",
    "\n",
    "    # PRCC\n",
    "    prcc_I = prcc(X, I_at_V)\n",
    "    prcc_P = prcc(X, Pmpp)\n",
    "\n",
    "    ranking = pd.DataFrame({\n",
    "        \"parameter\": param_names,\n",
    "        \"Spearman(I@V_eval)\": spearman_I,\n",
    "        \"PRCC(I@V_eval)\": prcc_I,\n",
    "        \"Spearman(Pmpp)\": spearman_P,\n",
    "        \"PRCC(Pmpp)\": prcc_P,\n",
    "        \"abs_PRCC(Pmpp)\": np.abs(prcc_P),\n",
    "    }).sort_values(\"abs_PRCC(Pmpp)\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    param_stats = samples.describe(percentiles=[0.05, 0.5, 0.95]).T[[\"mean\", \"std\", \"5%\", \"50%\", \"95%\"]]\n",
    "\n",
    "    return ranking, param_stats, I_at_V, Pmpp, samples\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ranking, param_stats, I_at_V, Pmpp, samples = monte_carlo_sensitivity_ddm(\n",
    "        N=3000,\n",
    "        seed=1,\n",
    "        V_eval=0.55,\n",
    "        Voc_guess=0.72,\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Parameter stats (sampled) ===\")\n",
    "    print(param_stats)\n",
    "\n",
    "    print(\"\\n=== Sensitivity ranking (sorted by |PRCC| on Pmpp) ===\")\n",
    "    print(ranking[[\"parameter\", \"PRCC(Pmpp)\", \"Spearman(Pmpp)\", \"PRCC(I@V_eval)\", \"Spearman(I@V_eval)\"]])\n",
    "\n",
    "    print(\"\\nPmpp summary:\\n\", pd.Series(Pmpp).describe())\n",
    "    print(\"\\nI(V_eval) summary:\\n\", pd.Series(I_at_V).describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38563dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Helper\n",
    "# =========================================================\n",
    "\n",
    "def normalize_0_1(img):\n",
    "    \"\"\"\n",
    "    Normalize grayscale image to range [0, 1].\n",
    "    \"\"\"\n",
    "    img = img.astype(np.float32)\n",
    "    return (img - img.min()) / (img.max() - img.min() + 1e-9)\n",
    "\n",
    "\n",
    "def coefficient_of_variation(img):\n",
    "    \"\"\"\n",
    "    CV = std / mean\n",
    "    \"\"\"\n",
    "    return img.std() / (img.mean() + 1e-9)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1) Iph from active area (EL 80%)\n",
    "# =========================================================\n",
    "\n",
    "def estimate_Iph(el80, Iph_ref=9.0, threshold=0.35):\n",
    "    \"\"\"\n",
    "    Iph proportional to active area.\n",
    "    \"\"\"\n",
    "    el80_n = normalize_0_1(el80)\n",
    "\n",
    "    active_pixels = el80_n > threshold\n",
    "    active_ratio = active_pixels.mean()\n",
    "\n",
    "    Iph = Iph_ref * active_ratio\n",
    "    return Iph, active_ratio\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2) Rs from EL 80% non-uniformity\n",
    "# =========================================================\n",
    "\n",
    "def estimate_Rs(el80, Rs_ref=0.35, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Rs increases with EL intensity non-uniformity.\n",
    "    \"\"\"\n",
    "    el80_n = normalize_0_1(el80)\n",
    "\n",
    "    cv = coefficient_of_variation(el80_n)\n",
    "    Rs = Rs_ref * (1.0 + alpha * cv)\n",
    "\n",
    "    return Rs, cv\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3) Rp from EL 20% uniformity (shunt proxy)\n",
    "# =========================================================\n",
    "\n",
    "def estimate_Rp(el20, Rp_ref=800.0, beta=1.0):\n",
    "    \"\"\"\n",
    "    Rp increases with EL uniformity at low current.\n",
    "    \"\"\"\n",
    "    el20_n = normalize_0_1(el20)\n",
    "\n",
    "    mean_intensity = el20_n.mean()\n",
    "    std_intensity = el20_n.std()\n",
    "\n",
    "    uniformity = mean_intensity / (std_intensity + 1e-9)\n",
    "    Rp = Rp_ref * (1.0 + beta * uniformity)\n",
    "\n",
    "    return Rp, uniformity\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4) All-in-one wrapper\n",
    "# =========================================================\n",
    "\n",
    "def estimate_parameters(el80, el20,\n",
    "                        Iph_ref=9.0,\n",
    "                        Rs_ref=0.35,\n",
    "                        Rp_ref=800.0,\n",
    "                        threshold=0.35,\n",
    "                        alpha=1.0,\n",
    "                        beta=1.0):\n",
    "    \"\"\"\n",
    "    Estimate Iph, Rs, Rp from grayscale EL images.\n",
    "    \"\"\"\n",
    "\n",
    "    Iph, active_ratio = estimate_Iph(el80, Iph_ref, threshold)\n",
    "    Rs, cv_80 = estimate_Rs(el80, Rs_ref, alpha)\n",
    "    Rp, uniformity_20 = estimate_Rp(el20, Rp_ref, beta)\n",
    "\n",
    "    return {\n",
    "        \"Iph\": Iph,\n",
    "        \"Rs\": Rs,\n",
    "        \"Rp\": Rp,\n",
    "        \"active_ratio\": active_ratio,\n",
    "        \"cv_80\": cv_80,\n",
    "        \"uniformity_20\": uniformity_20\n",
    "    }\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Example usage\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    el80 = np.load(\"el_80.npy\")   # or cv2.imread(..., IMREAD_GRAYSCALE)\n",
    "    el20 = np.load(\"el_20.npy\")\n",
    "\n",
    "    params = estimate_parameters(\n",
    "        el80, el20,\n",
    "        Iph_ref=9.0,\n",
    "        Rs_ref=0.35,\n",
    "        Rp_ref=800.0,\n",
    "        threshold=0.35,\n",
    "        alpha=1.0,\n",
    "        beta=1.0\n",
    "    )\n",
    "\n",
    "    for k, v in params.items():\n",
    "        print(f\"{k:>15}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f5e2da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          nama_gambar       mean  median  modus\n",
      "0     10084_35_1_01272020_20_wrp.tiff  89.951571    95.0    102\n",
      "1     10084_35_1_01272020_80_wrp.tiff  67.735187    70.0     70\n",
      "2     10084_35_1_02222021_20_wrp.tiff  88.351796   105.0      5\n",
      "3     10084_35_1_02222021_80_wrp.tiff  72.874862    85.0      6\n",
      "4     10085_35_1_01272020_20_wrp.tiff  82.821786    86.0     77\n",
      "...                               ...        ...     ...    ...\n",
      "1191   4856_32_2_11022021_80_wrp.tiff  88.378453    93.0     12\n",
      "1192   4857_32_2_11022021_20_wrp.tiff  89.341477    96.0     12\n",
      "1193   4857_32_2_11022021_80_wrp.tiff  88.050140    94.0     12\n",
      "1194   4896_32_2_10262021_20_wrp.tiff  99.791134   109.0     13\n",
      "1195   4896_32_2_10262021_80_wrp.tiff  91.201926    98.0     12\n",
      "\n",
      "[1196 rows x 4 columns]\n",
      "\n",
      "Saved: pixel_stats.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# CONFIG\n",
    "# ==============================\n",
    "INPUT_DIR = r\"C:\\Users\\Ghozy Abror\\OneDrive - Institut Teknologi Bandung\\Karirku\\UNSW\\Thesis\\Coding\\EL\\EL_wrp\"   # <-- ganti folder kamu\n",
    "REMOVE_VALUES = {0, 1}                       # nilai yang mau dieliminasi\n",
    "SAVE_CSV = True\n",
    "OUTPUT_CSV = \"pixel_stats.csv\"\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# CORE FUNCTIONS\n",
    "# ==============================\n",
    "def read_grayscale_tiff(path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Read TIFF as grayscale (uint8). Assumes image is already 8-bit grayscale.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Cannot read image: {path}\")\n",
    "\n",
    "    # If somehow read as multi-channel, convert to grayscale\n",
    "    if img.ndim == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Ensure uint8\n",
    "    if img.dtype != np.uint8:\n",
    "        # still handle safely\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def remove_values(img: np.ndarray, values_to_remove={0, 1}) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return 1D array of pixels after removing certain values (e.g., 0 and 1).\n",
    "    \"\"\"\n",
    "    mask = np.ones_like(img, dtype=bool)\n",
    "    for v in values_to_remove:\n",
    "        mask &= (img != v)\n",
    "    return img[mask].ravel()\n",
    "\n",
    "\n",
    "def compute_stats(pixels_1d: np.ndarray):\n",
    "    \"\"\"\n",
    "    Compute mean, median, mode for uint8 pixel values.\n",
    "    Mode computed via bincount (fast for 0..255).\n",
    "    \"\"\"\n",
    "    if pixels_1d.size == 0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    mean_val = float(pixels_1d.mean())\n",
    "    median_val = float(np.median(pixels_1d))\n",
    "\n",
    "    # Mode (most frequent value)\n",
    "    counts = np.bincount(pixels_1d, minlength=256)  # because uint8\n",
    "    mode_val = int(np.argmax(counts))\n",
    "\n",
    "    return mean_val, median_val, mode_val\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# MAIN PIPELINE\n",
    "# ==============================\n",
    "def build_pixel_stats_table(input_dir: str, remove_vals={0, 1}) -> pd.DataFrame:\n",
    "    folder = Path(input_dir)\n",
    "    if not folder.exists():\n",
    "        raise FileNotFoundError(f\"Folder not found: {folder}\")\n",
    "\n",
    "    # collect tif/tiff\n",
    "    image_paths = sorted(list(folder.glob(\"*.tif\")) + list(folder.glob(\"*.tiff\")))\n",
    "\n",
    "    rows = []\n",
    "    for p in image_paths:\n",
    "        img = read_grayscale_tiff(p)\n",
    "        pixels = remove_values(img, remove_vals)\n",
    "        mean_val, median_val, mode_val = compute_stats(pixels)\n",
    "\n",
    "        rows.append({\n",
    "            \"nama_gambar\": p.name,\n",
    "            \"mean\": mean_val,\n",
    "            \"median\": median_val,\n",
    "            \"modus\": mode_val\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = build_pixel_stats_table(INPUT_DIR, REMOVE_VALUES)\n",
    "    print(df)\n",
    "\n",
    "    if SAVE_CSV:\n",
    "        df.to_csv(OUTPUT_CSV, index=False)\n",
    "        print(f\"\\nSaved: {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb90b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          nama_gambar       mean  median  modus  mean_relative\n",
      "0     10084_35_1_01272020_20_wrp.tiff  89.951571    95.0    102       0.473429\n",
      "1     10084_35_1_01272020_80_wrp.tiff  67.735187    70.0     70       0.378409\n",
      "2     10084_35_1_02222021_20_wrp.tiff  88.351796   105.0      5       0.450774\n",
      "3     10084_35_1_02222021_80_wrp.tiff  72.874862    85.0      6       0.385581\n",
      "4     10085_35_1_01272020_20_wrp.tiff  82.821786    86.0     77       0.452578\n",
      "...                               ...        ...     ...    ...            ...\n",
      "1191   4856_32_2_11022021_80_wrp.tiff  88.378453    93.0     12       0.392793\n",
      "1192   4857_32_2_11022021_20_wrp.tiff  89.341477    96.0     12       0.446707\n",
      "1193   4857_32_2_11022021_80_wrp.tiff  88.050140    94.0     12       0.421293\n",
      "1194   4896_32_2_10262021_20_wrp.tiff  99.791134   109.0     13       0.498956\n",
      "1195   4896_32_2_10262021_80_wrp.tiff  91.201926    98.0     12       0.357655\n",
      "\n",
      "[1196 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "\n",
    "INPUT_DIR = r\"C:\\Users\\Ghozy Abror\\OneDrive - Institut Teknologi Bandung\\Karirku\\UNSW\\Thesis\\Coding\\EL\\EL_wrp\"   # <-- ganti folder kamu\n",
    "REMOVE_VALUES = {0, 1}\n",
    "\n",
    "\n",
    "def read_grayscale_tiff(path: Path):\n",
    "    img = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Cannot read image: {path}\")\n",
    "\n",
    "    if img.ndim == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "\n",
    "def remove_values(img, values_to_remove={0, 1}):\n",
    "    mask = np.ones_like(img, dtype=bool)\n",
    "    for v in values_to_remove:\n",
    "        mask &= (img != v)\n",
    "    return img[mask].ravel()\n",
    "\n",
    "\n",
    "def compute_stats(pixels_1d, panel_max):\n",
    "    if pixels_1d.size == 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    mean_val = float(pixels_1d.mean())\n",
    "    median_val = float(np.median(pixels_1d))\n",
    "\n",
    "    counts = np.bincount(pixels_1d, minlength=256)\n",
    "    mode_val = int(np.argmax(counts))\n",
    "\n",
    "    # Intensitas relatif terhadap pixel paling terang di panel\n",
    "    mean_relative = mean_val / (panel_max + 1e-9)\n",
    "\n",
    "    return mean_val, median_val, mode_val, mean_relative\n",
    "\n",
    "\n",
    "def build_pixel_stats_table(input_dir, remove_vals={0, 1}):\n",
    "    folder = Path(input_dir)\n",
    "    image_paths = sorted(list(folder.glob(\"*.tif\")) +\n",
    "                         list(folder.glob(\"*.tiff\")))\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for p in image_paths:\n",
    "        img = read_grayscale_tiff(p)\n",
    "\n",
    "        panel_max = img.max()   # pixel paling terang di panel\n",
    "        pixels = remove_values(img, remove_vals)\n",
    "\n",
    "        mean_val, median_val, mode_val, mean_rel = compute_stats(\n",
    "            pixels, panel_max\n",
    "        )\n",
    "\n",
    "        rows.append({\n",
    "            \"nama_gambar\": p.name,\n",
    "            \"mean\": mean_val,\n",
    "            \"median\": median_val,\n",
    "            \"modus\": mode_val,\n",
    "            \"mean_relative\": mean_rel\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = build_pixel_stats_table(INPUT_DIR, REMOVE_VALUES)\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efde557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"pixel_stats_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e1ba6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNSWThesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
